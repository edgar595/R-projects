"0","library(finetune)"
"2","Warning:"
"2"," package â€˜finetuneâ€™ was built under R version 4.2.3
"
"0","doParallel::registerDoParallel()"
"0",""
"0","set.seed(234)"
"0","xgb_word_rs <- tune_race_anova("
"0","    xgb_word_wf,"
"0","    austin_folds,"
"0","    grid = xgb_grid,"
"0","    metrics = metric_set(mn_log_loss),"
"0","    control = control_race(verbose_elim = TRUE)"
"0","  )"
"1","[38;5;232m[30mâ„¹ Evaluating against the initial 3 burn-in resamples.[38;5;232m[39m
"
"1","[38;5;232m[30mâ„¹ Racing will minimize the mn_log_loss metric.[38;5;232m[39m
"
"1","[38;5;232m[30mâ„¹ Resamples are analyzed in a random order.[38;5;232m[39m
"
"1","[30mâ„¹ Fold5: 13 eliminated; 7 candidates remain.[39m
"
"1","[30mâ„¹ Fold4: 4 eliminated; 3 candidates remain.[39m
"
"0","xgb_word_rs"
"1","# Tuning results
"
"1","#"
"1"," "
"1","5-fold cross-validation using stratification"
"1"," "
"1","
"
